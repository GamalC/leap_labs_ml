# ReadMe

## To use
1. The model used is the pretrained MNIST model which can be downloaded from [this link](https://www.example.com).
2. Place downloaded file where it can be accessed by the _orignal_model_path_ variable in the _adversarial_attack.py_ file.
3. The code does not currently support passing arguments from the terminal. The target label for the attack should be specified by the _target_label_ variable in the code when running the script.
4. Setup by installing the contents of requirements.txt in a virtual environment.
5. Run with command __python adversarial_attack.py__. 
